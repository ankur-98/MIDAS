{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "xTuFMB_ONdU6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Python Problem\n",
        "To write a python script to fetch all the tweets(as many as allowed by Twitter API) done by midas@IIITD twitter handle and dump the responses into JSONlines file. Further, parse these JSONline files to display the following for every tweet in a tabular format.\n",
        "\n",
        "* The text of the tweet.\n",
        "* Date and time of the tweet.\n",
        "* The number of favorites/likes.\n",
        "* The number of retweets.\n",
        "* Number of Images present in Tweet. If no image returns None.\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "iR4gIlAyn3XS"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Installing the required Libraries"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8ae0c609-7d46-46bb-a247-0d9be14abf4e",
        "id": "mRqd89RLn3Wi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#!pip install jsonlines"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dhNpxYg6SA2Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries & Setting up API Credentials"
      ]
    },
    {
      "metadata": {
        "id": "R0i7yIGpRzD-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import jsonlines\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "\n",
        "credentials = {'consumer_key':'',\n",
        "               'consumer_secret':'',\n",
        "               'access_token':'',\n",
        "               'access_token_secret':''}\n",
        "\n",
        "auth = tweepy.OAuthHandler(credentials['consumer_key'], credentials['consumer_secret'])\n",
        "auth.set_access_token(credentials['access_token'], credentials['access_token_secret'])\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tx4_-H4Qp7TV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Scrapping Tweets from @midasIIITD and Writting them to JSONlines File"
      ]
    },
    {
      "metadata": {
        "id": "h-lQJgr-qML2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tweets = api.user_timeline(screen_name='midasiiitd',count=100)\n",
        "tweets = [i._json for i in tweets]\n",
        "with open('output.jsonl', 'w') as fp:\n",
        "  writer = jsonlines.Writer(fp)\n",
        "  writer.write_all(tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zOra929Vqj0-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Parsing Tweets using the Summarize Function\n",
        "\n",
        "Takes input of the complete Tweet and returns a parsed Json"
      ]
    },
    {
      "metadata": {
        "id": "iE77TsbNsPnG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def summarize(tweet):\n",
        "    new_tweet = {}\n",
        "    \n",
        "    for label in [\"text\", \"created_at\", \"favorite_count\", \"retweet_count\", \"favorite_count\"]:\n",
        "      new_tweet[label] = tweet[label]\n",
        "      \n",
        "    new_tweet[\"media_count\"] = 0    #initialize counter\n",
        "    \n",
        "    try:    #try if media exists or not\n",
        "      for m in tweet['extended_entities']['media']:\n",
        "          if m[\"type\"] == 'photo':\n",
        "              new_tweet[\"media_count\"] = new_tweet[\"media_count\"]+1   #increment counter\n",
        "    except:\n",
        "      new_tweet[\"media_count\"]=None\n",
        "      \n",
        "      \n",
        "    if new_tweet[\"media_count\"] == 0:\n",
        "      new_tweet[\"media_count\"] = None\n",
        "    \n",
        "    return new_tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tCCIwFNy2ZfP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read JSONlines File and get Parsed JSON to form the Table\n",
        "\n",
        "JSONs are parsed line by line using an itererator. The parsed JSON of every tweet appends each element to the dictionary 'd' containg all the columns. THe dictionary 'd is used to form the dataframe and hence represented as a Table."
      ]
    },
    {
      "metadata": {
        "id": "LfItg4Me3Fby",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d = {\"text\": [], \"created_at\": [], \"favorite_count\": [], \"retweet_count\": [], \"favorite_count\": [], \"media_count\": []}\n",
        "\n",
        "with open('output.jsonl', 'r') as fp:   #Read the JSONlines file\n",
        "  with jsonlines.Reader(fp) as reader:\n",
        "    it = iter(reader)\n",
        "    \n",
        "    while(True):\n",
        "      try:\n",
        "        json = summarize(next(it))     #Iterate line by line in JSONlines file\n",
        "        for column in list(json.keys()):\n",
        "          d[column].append(json[column])\n",
        "      \n",
        "      except:   #To stop without interuption when iter() ends\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3GXyGpIx3p6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1134
        },
        "outputId": "356be8d4-3656-43e0-b7cd-30e92cca7947"
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(d)\n",
        "df = df.where((pd.notnull(df)), None)\n",
        "df.sample(35)    #Print Table with sample of 35 tweets"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>media_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Tue Feb 05 11:55:41 +0000 2019</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>Thanks, Karan Uppal and @RatnRajiv for all you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Thu Feb 21 16:27:54 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>13</td>\n",
              "      <td>RT @kdnuggets: #AI for Social Good study - how...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Sat Mar 16 09:20:29 +0000 2019</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>IEEE BigMM 2019 - Call for Workshop Proposals....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Sun Mar 03 14:55:31 +0000 2019</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>Considering several requests to extend the dea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Mon Feb 18 05:37:59 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>6</td>\n",
              "      <td>RT @CornellDyson: Digital ag is Cornell’s newe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Fri Mar 08 13:15:34 +0000 2019</td>\n",
              "      <td>8</td>\n",
              "      <td>None</td>\n",
              "      <td>4</td>\n",
              "      <td>We are in the process of finalizing the shortl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Sun Feb 17 09:02:28 +0000 2019</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>Looking forward to your participation in Multi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Wed Feb 13 18:56:13 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>RT @kdnuggets: Using BERT for state-of-the-art...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Wed Mar 06 11:12:30 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>RT @kdnuggets: Python Data Science for Beginne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Wed Feb 20 05:38:29 +0000 2019</td>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>Deepak Gupta, has joined @Google today. \\nEarl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>Tue Jan 29 18:05:01 +0000 2019</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>@TechAtBloomberg @debanjanbhucs It is a great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Tue Jan 29 04:40:47 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>5</td>\n",
              "      <td>RT @TechAtBloomberg: #Textanalytics researcher...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Tue Feb 19 04:19:05 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>292</td>\n",
              "      <td>RT @technology: What could the manufacturing i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Mon Feb 25 16:10:46 +0000 2019</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>We will process all applications received by M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Wed Feb 20 07:09:19 +0000 2019</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>@RealAAAI @RatnRajiv Thanks, @RealAAAI for rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Tue Mar 12 17:43:44 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>67</td>\n",
              "      <td>RT @kaggle: Bookmark this amazing library of i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Mon Jan 28 12:11:13 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>18</td>\n",
              "      <td>RT @Princeton: Using data from more than 6,000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Tue Feb 19 04:18:53 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>21</td>\n",
              "      <td>RT @MSFTResearch: Dr. Layla El Asri wants you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Sun Mar 03 15:37:28 +0000 2019</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>At @midasIIITD, we not only work hard but also...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Tue Feb 26 18:30:52 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>RT @RatnRajiv: Great meeting with @midasIIITD ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Thu Jan 31 05:50:19 +0000 2019</td>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>@midasIIITD Lab is pleased to share our novel ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Sun Mar 03 14:26:40 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>315</td>\n",
              "      <td>RT @jeremyphoward: 39 studies about human perc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Sun Feb 17 08:49:36 +0000 2019</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>Consider attending National Workshop on Intell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Thu Feb 21 04:48:24 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>13</td>\n",
              "      <td>RT @radamihalcea: We tend to focus mainly on c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Fri Feb 01 07:46:57 +0000 2019</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>@the_dhumketu @RealAAAI Congrats! Raghav, Kshi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Tue Feb 05 11:06:31 +0000 2019</td>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>@midasIIITD performance in OffensEval 2019 (Se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Tue Jan 29 05:17:27 +0000 2019</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>@TechAtBloomberg @debanjanbhucs @IIITDelhi @Ra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Thu Feb 21 06:39:27 +0000 2019</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>@IIITDelhi has initiated PhD Admission 2019 pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sun Mar 24 18:44:01 +0000 2019</td>\n",
              "      <td>8</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>The last date for submitting a solution for th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Fri Mar 08 13:22:07 +0000 2019</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@AvinashSwamina2 @IIITDelhi No. They will be g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Mon Feb 18 17:29:44 +0000 2019</td>\n",
              "      <td>11</td>\n",
              "      <td>None</td>\n",
              "      <td>9</td>\n",
              "      <td>To apply for @midasIIITD internship at @IIITDe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>Mon Feb 04 12:16:16 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>39</td>\n",
              "      <td>RT @ProfAnirban: One of the biggest obstacles ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Fri Feb 01 03:15:27 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>8</td>\n",
              "      <td>RT @PeterMartigny: Very interesting talk by @C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sun Mar 24 06:23:14 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>RT @IEEEBigMM19: Distinguished researchers Dr....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Sun Feb 17 17:22:06 +0000 2019</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>50</td>\n",
              "      <td>RT @odsc: Introduction to StanfordNLP: a state...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        created_at  favorite_count media_count  retweet_count  \\\n",
              "72  Tue Feb 05 11:55:41 +0000 2019               1        None              1   \n",
              "42  Thu Feb 21 16:27:54 +0000 2019               0        None             13   \n",
              "11  Sat Mar 16 09:20:29 +0000 2019               1        None              1   \n",
              "31  Sun Mar 03 14:55:31 +0000 2019               6        None              2   \n",
              "52  Mon Feb 18 05:37:59 +0000 2019               0        None              6   \n",
              "25  Fri Mar 08 13:15:34 +0000 2019               8        None              4   \n",
              "54  Sun Feb 17 09:02:28 +0000 2019               3        None              1   \n",
              "60  Wed Feb 13 18:56:13 +0000 2019               0           1              5   \n",
              "27  Wed Mar 06 11:12:30 +0000 2019               0           1             22   \n",
              "46  Wed Feb 20 05:38:29 +0000 2019               4        None              2   \n",
              "90  Tue Jan 29 18:05:01 +0000 2019               5        None              2   \n",
              "95  Tue Jan 29 04:40:47 +0000 2019               0        None              5   \n",
              "49  Tue Feb 19 04:19:05 +0000 2019               0        None            292   \n",
              "38  Mon Feb 25 16:10:46 +0000 2019               2        None              1   \n",
              "45  Wed Feb 20 07:09:19 +0000 2019               6        None              2   \n",
              "17  Tue Mar 12 17:43:44 +0000 2019               0        None             67   \n",
              "97  Mon Jan 28 12:11:13 +0000 2019               0        None             18   \n",
              "50  Tue Feb 19 04:18:53 +0000 2019               0        None             21   \n",
              "30  Sun Mar 03 15:37:28 +0000 2019               9        None              1   \n",
              "36  Tue Feb 26 18:30:52 +0000 2019               0        None              1   \n",
              "82  Thu Jan 31 05:50:19 +0000 2019               4        None              2   \n",
              "32  Sun Mar 03 14:26:40 +0000 2019               0        None            315   \n",
              "55  Sun Feb 17 08:49:36 +0000 2019               1        None              0   \n",
              "44  Thu Feb 21 04:48:24 +0000 2019               0        None             13   \n",
              "77  Fri Feb 01 07:46:57 +0000 2019               3        None              1   \n",
              "73  Tue Feb 05 11:06:31 +0000 2019               4        None              3   \n",
              "94  Tue Jan 29 05:17:27 +0000 2019               3           2              1   \n",
              "43  Thu Feb 21 06:39:27 +0000 2019               2        None              1   \n",
              "1   Sun Mar 24 18:44:01 +0000 2019               8        None              3   \n",
              "24  Fri Mar 08 13:22:07 +0000 2019               1        None              0   \n",
              "51  Mon Feb 18 17:29:44 +0000 2019              11        None              9   \n",
              "74  Mon Feb 04 12:16:16 +0000 2019               0        None             39   \n",
              "79  Fri Feb 01 03:15:27 +0000 2019               0        None              8   \n",
              "5   Sun Mar 24 06:23:14 +0000 2019               0        None              3   \n",
              "53  Sun Feb 17 17:22:06 +0000 2019               0        None             50   \n",
              "\n",
              "                                                 text  \n",
              "72  Thanks, Karan Uppal and @RatnRajiv for all you...  \n",
              "42  RT @kdnuggets: #AI for Social Good study - how...  \n",
              "11  IEEE BigMM 2019 - Call for Workshop Proposals....  \n",
              "31  Considering several requests to extend the dea...  \n",
              "52  RT @CornellDyson: Digital ag is Cornell’s newe...  \n",
              "25  We are in the process of finalizing the shortl...  \n",
              "54  Looking forward to your participation in Multi...  \n",
              "60  RT @kdnuggets: Using BERT for state-of-the-art...  \n",
              "27  RT @kdnuggets: Python Data Science for Beginne...  \n",
              "46  Deepak Gupta, has joined @Google today. \\nEarl...  \n",
              "90  @TechAtBloomberg @debanjanbhucs It is a great ...  \n",
              "95  RT @TechAtBloomberg: #Textanalytics researcher...  \n",
              "49  RT @technology: What could the manufacturing i...  \n",
              "38  We will process all applications received by M...  \n",
              "45  @RealAAAI @RatnRajiv Thanks, @RealAAAI for rec...  \n",
              "17  RT @kaggle: Bookmark this amazing library of i...  \n",
              "97  RT @Princeton: Using data from more than 6,000...  \n",
              "50  RT @MSFTResearch: Dr. Layla El Asri wants you ...  \n",
              "30  At @midasIIITD, we not only work hard but also...  \n",
              "36  RT @RatnRajiv: Great meeting with @midasIIITD ...  \n",
              "82  @midasIIITD Lab is pleased to share our novel ...  \n",
              "32  RT @jeremyphoward: 39 studies about human perc...  \n",
              "55  Consider attending National Workshop on Intell...  \n",
              "44  RT @radamihalcea: We tend to focus mainly on c...  \n",
              "77  @the_dhumketu @RealAAAI Congrats! Raghav, Kshi...  \n",
              "73  @midasIIITD performance in OffensEval 2019 (Se...  \n",
              "94  @TechAtBloomberg @debanjanbhucs @IIITDelhi @Ra...  \n",
              "43  @IIITDelhi has initiated PhD Admission 2019 pr...  \n",
              "1   The last date for submitting a solution for th...  \n",
              "24  @AvinashSwamina2 @IIITDelhi No. They will be g...  \n",
              "51  To apply for @midasIIITD internship at @IIITDe...  \n",
              "74  RT @ProfAnirban: One of the biggest obstacles ...  \n",
              "79  RT @PeterMartigny: Very interesting talk by @C...  \n",
              "5   RT @IEEEBigMM19: Distinguished researchers Dr....  \n",
              "53  RT @odsc: Introduction to StanfordNLP: a state...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "Kj6XHAIqJz0_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}